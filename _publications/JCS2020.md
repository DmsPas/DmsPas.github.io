---
title: "Block-enhanced precision matrix estimation for large-scale datasets"
pubtype: "Journal"
collection: publications
permalink: /publication/JCS2020
date: 2020-07-18
venue: "Journal of Computational Science"
paperurl: 'https://doi.org/10.1016/j.jocs.2021.101389'
citation: 'A. Eftekhari, D. Pasadakis, M. Bollhöfer, S. Scheidegger, and O. Schenk, Block-enhanced precision matrix estimation for large-scale datasets, Journal of Computational Science, Volume 53, 2021, 101389, ISSN 1877-7503'
---
The ℓ1-regularized Gaussian maximum likelihood method is a common approach for sparse precision
matrix estimation, but one that poses a computational challenge for high-dimensional datasets. We
present a novel ℓ1-regularized maximum likelihood method for performant large-scale sparse precision
matrix estimation utilizing the block structures in the underlying computations. We identify the computational bottlenecks and contribute a block coordinate descent update as well as a block approximate matrix inversion routine, which is then parallelized using a shared-memory scheme. We demonstrate the effectiveness, accuracy, and performance of these algorithms. Our numerical examples and comparative results with various modern open-source packages reveal that these precision matrix estimation methods can accelerate the computation of covariance matrices by two to three orders of magnitude, while keeping memory requirements modest. Furthermore, we conduct large-scale case studies for applications from finance and medicine with several thousand random variables to demonstrate applicability for real-world datasets.



[DOI](https://doi.org/10.1016/j.jocs.2021.101389)

